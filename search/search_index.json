{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About the Scripta Compiler (( This document is very much a work in progress. )) The Scripta compiler translates source text written in a markup language to an Elm representation of Html. The markup languages supported are L0 microLaTeX XMarkdown The compiler provides interactive, real-time editing with error recovery for these languages. Demos & Apps Simple Demo Scripta Desktop Scripta.io Scripta.io is an editing, document management, and publishing system. Scripta Desktop is simple editing app. Both Scripta Desktop and Scripta.io make use of error recovery, while the simple demo does not. Docs and Videos Compiler documentation Scripta.io documentation Conference talk at Lambda Days \u2014 an outline of the error recovery strategy. Code (open-source) This project has been partially supported by the Simons Foundation. We thank them for their generosity. Contact: James Carlson jxxcarlson at gmail @jxxcarlson on the Elm Slack @epsilon2718 on Twitter","title":"Home"},{"location":"#about-the-scripta-compiler","text":"(( This document is very much a work in progress. )) The Scripta compiler translates source text written in a markup language to an Elm representation of Html. The markup languages supported are L0 microLaTeX XMarkdown The compiler provides interactive, real-time editing with error recovery for these languages. Demos & Apps Simple Demo Scripta Desktop Scripta.io Scripta.io is an editing, document management, and publishing system. Scripta Desktop is simple editing app. Both Scripta Desktop and Scripta.io make use of error recovery, while the simple demo does not. Docs and Videos Compiler documentation Scripta.io documentation Conference talk at Lambda Days \u2014 an outline of the error recovery strategy. Code (open-source) This project has been partially supported by the Simons Foundation. We thank them for their generosity. Contact: James Carlson jxxcarlson at gmail @jxxcarlson on the Elm Slack @epsilon2718 on Twitter","title":"About the Scripta Compiler"},{"location":"common-code/","text":"Common Code Functional loops Functional loops are used throughout the compiler, and in particular in the L0 parser. The key element of such a loop is a driver function f : state -> Step state a that does some computation on the state and returns either a value of type Done a or a value of type Loop state . In the first case the loop terminates with the indicated value. In the second case it runs again with the new state value.\u02dc -- Parser.Helpers type Step state a = Loop state | Done a loop : state -> (state -> Step state a) -> a loop s f = case f s of Loop s_ -> loop s_ f Done b -> b","title":"Common Code"},{"location":"common-code/#common-code","text":"","title":"Common Code"},{"location":"common-code/#functional-loops","text":"Functional loops are used throughout the compiler, and in particular in the L0 parser. The key element of such a loop is a driver function f : state -> Step state a that does some computation on the state and returns either a value of type Done a or a value of type Loop state . In the first case the loop terminates with the indicated value. In the second case it runs again with the new state value.\u02dc -- Parser.Helpers type Step state a = Loop state | Done a loop : state -> (state -> Step state a) -> a loop s f = case f s of Loop s_ -> loop s_ f Done b -> b","title":"Functional loops"},{"location":"dataStructures/","text":"Data Structures The primary data structures of the parser are Primitive Blocks ( PrimitiveBlock ) Expressions ( Expr ) Expression blocks ( ExpressionBlock ) Accumulator ( Accumulator ) The parser first breaks source text into primitive blocks (1), then maps the internal language parser over a list of primitive blocks to produce expression blocks (3). Finally, the function transformAccumulate is mapped over the list of expression blocks, simultaneously collecting information such as cross-references and updating the list of expression blocks with that information Primitive Blocks Blocks have the rather elaborate type listed below. This complex structure is necessary for interactive real-time editing with error recovery. By real-time we mean that the rendered text is updated \"instantaneously\" in the browser as the user types in text. By interactive, we mean (for example) that click on the rendered text brings the associated source text into view while simultaneously highlighting it. In addition, if the user selects a block of source text and presses ctrl-S (S for 'sync'), the corresponding rendered text is brought into view and highlighted. In the case of L0 and XMarkdown, a primitive block is defined by -- Parser.PrimitiveBlock type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status . Example (L0) Consider the block | theorem (Magnus Axelsson) note:this is a joke temperature:22 If $a = b$ then $b = a$. There \"(Magnus Axelsson) note:this is a joke temperature:22\" is the argument string. This string is a sequences of words. Normal words do not contain the \":\" character. Words of the form a:b , where a is normal are key-value words, representing key-value pairs. Normal words must precede key-value words. The former make up the argument list, whereas the latter define the entries of the property dictionary. Thus we have args = [\"(Magnus\", \"Axellson)\"] properties = Dict.fromList [(\"note\", \"this is a joke\"), (\"temperature\", \"22\")] Arguments and properties are treated the same for verbatim blocks as for ordinary blocks. Example (MicroLaTeX) Below is a LaTeX environment with an LaTeX optional argument. In this case the args list is empty and their are three key-value pairs in the properties dictiononary \\begin{theorem}[foo:1, hoho:a b c, bar:2] If $a = b$ then $b = a$ \\end{theorem} args = [] properties = Dict.fromList [(\"bar\", \"2\"), (\"foo\", \"1\"), (\"hoho\", \"a b c\"] At the moment, environments with normal arguemnts are not handled, e.g., \\begin{theorem}{X}{Y}[foo:1, hoho:a b c, bar:2] If $a = b$ then $b = a$ \\end{theorem} This should produce args = [\"X\", \"Y\"] Coercion and Pseudoblocks Certain constructs such as \\image{https://yadayada.org/sparrow.jpg width:300} or \\item foo bar ... look to be syntactically part of the surface internal language of MicroLaTeX. However, in source text they alway appear with an empty line above and below and so are parsed as an anonymous (paragraph) block. They must be coerced into being an ordinary or verbatim block, e.g., { name = \"image\" , blockType = PBVerbatim , properties = Dict.fromList [(\"width\", \"200\")] , content = [\"image{https://yadayada.org/sparrow.jpg\"] ... } or { name = \"image\" , blockType = PBOrdinary , content = [\"foo bar ...\"] ... } This coercion is accomplished by functions in module MicroLaTeX.Parser.Transform , e.g., -- module MicroLaTeX.Parser.Transform handlePseudoBlockWithContent : String -> Maybe String -> PrimitiveBlock -> PrimitiveBlock handlePseudoBlockWithContent name maybeArg block = ... handleImage : PrimitiveBlock -> PrimitiveBlock The names of these elements must appear in the pseudoBlockNamesWithContent list: -- module MicroLaTeX.Parser.Transform pseudoBlockNamesWithContent = [ \"title\", \"section\", \"subsection\", \"subsubsection\" , \"subheading\", \"setcounter\", \"contents\", \"endnotes\", \"image\" ] Expressions -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta Expression Blocks -- Parser.Block type ExpressionBlock = ExpressionBlock { name : Maybe String , args : List String , properties : Dict String String , indent : Int , lineNumber : Int , numberOfLines : Int , id : String , tag : String , blockType : BlockType , content : Either String (List Expr) , messages : List String , sourceText : String , error : Maybe { error : String } } Edit records Module: Compiler.AbstractDifferentialCompiler To manage differential compilation, one uses EditRecords . The main idea is to keep track of the current list of primitive blocks ( List chunk ) and the current parse structure ( tree ). When an edit is made, the source is parsed into primitive blocks and the new and old lists are compared, producing a diff record which shows which blocks have been changed. The changed blocks are parsed, then incorporated into the current list of expression blocks ( List parsedChunk ). type alias EditRecord chunk parsedChunk accumulator = { chunks : List chunk , parsed : List parsedChunk , tree : List (Tree parsedChunk) , accumulator : accumulator , lang : Language , messages : List String , initialData : InitialData } Orchestration of the process outlined above is conducted by the update function listed below. -- Compiler.AbstractDifferentialParser update : UpdateFunctions chunk parsedChunk acc -> String -> EditRecord chunk parsedChunk acc -> EditRecord chunk parsedChunk acc The first argument is a record that holds the functions needed in any concrete instantiation of the update function, e.g, the field setLineNumber : Int -> parsedChunk -> parsedChunk used in renumbering parsed chunks. XX: more on keeping the line numbers up-to-data. Diff Records Module: Compiler.Differ Let u and v be two lists of things of type p . Write them as u = axb, v = ayb, where a is the greatest common prefix and b is the greatest common suffix. Return DiffRecord a b x y. The type parameter can be anything: characters, strings, primitive blocks, etc. In the example below, p = Char . type alias DiffRecord p = { commonPrefix : List p , commonSuffix : List p , middleSegmentInSource : List p , middleSegmentInTarget : List p } Example > import Compiler.Differ exposing(..) > a = \"abcxyzdef\" |> String.split \"\" [\"a\",\"b\",\"c\",\"x\",\"y\",\"z\",\"d\",\"e\",\"f\"] : List String > b = \"abcXYZdef\" |> String.split \"\" [\"a\",\"b\",\"c\",\"X\",\"Y\",\"Z\",\"d\",\"e\",\"f\"] : List String > diff a b { commonPrefix = [\"a\",\"b\",\"c\"] , commonSuffix = [\"d\",\"e\",\"f\"], , middleSegmentInSource = [\"x\",\"y\",\"z\"] , middleSegmentInTarget = [\"X\",\"Y\",\"Z\"] } Diffing a Forest Module: Compiler.DifferForest The diff function in this module is designed to diff lists with an implicit forest structure (list of trees) defined by a function level: p -> Int . In the resulting DiffRecord , the prefix, suffix, and middle segments all represent subforests. The diff function in this module is used to diff primitive blocks in the compiler. diff : (p -> p -> Bool) -> (p -> Int) -> List p -> List p -> DiffRecord p diff eq level u v = The function eq: p -> p -> Bool tests for equality ... XX: more detail. In the case of primitive blocks ... important that line numbers be properly computed in the common suffix ... To illustrate the main issue, consider the lists u and v (below). These have an indentation structure like an outline for an article, and so define the structure of a forest. In the example below, the leaf jkl in the tree with root def is changed to JKL . u: ---- abc def ghi jkl mno pqr v: ---- abc def ghi JKL mno pqr In this example the diff record represents the following structure: commonPrefix: ---- abc middleSegmentInSource: --- def ghi jkl mno middleSegmentInTarget: --- def ghi JKL mno commonSuffix: --- pqr XX, Expand on this, explain it: -- IMPORTANT: taking y from v, the second argument -- ensures that the line numbers in the common suffix -- are correct Accumulator Module: Compiler.Acc The Accumulator type is used to collect, build up, and apply auxiliary information about the text. For example, the headingIndex stores the current section number, where \"current\" refers to the the current section of the document as the accumulator-building function walks through the current parse forest. As it does, it simultaneously (1) updates the accumulator and (2) applies new \"patches\" of the accumulator to the parse forest. This process is managed by function transformAccumulateTree which is called every time the parser pipeline runs. For this reason one does not have to recompile to have up-to-date cross-references, etc., as in standard LaTeX. transformAccumulate : InitialAccumulatorData -> Forest ExpressionBlock -> ( Accumulator, Forest ExpressionBlock ) Type definition: -- Compiler.Acc type alias Accumulator = { language : Language , headingIndex : Vector , documentIndex : Vector , counter : Dict String Int , blockCounter : Int , itemVector : Vector -- Used for section numbering , numberedItemDict : Dict String { level : Int, index : Int } , numberedBlockNames : List String , inList : Bool , reference : Dict String { id : String, numRef : String } , terms : Dict String TermLoc , footnotes : Dict String TermLoc , footnoteNumbers : Dict String Int , mathMacroDict : Parser.MathMacro.MathMacroDict , textMacroDict : Dict String Macro , keyValueDict : Dict String String , qAndAList : List ( String, String ) , qAndADict : Dict String String }","title":"Data Structures"},{"location":"dataStructures/#data-structures","text":"The primary data structures of the parser are Primitive Blocks ( PrimitiveBlock ) Expressions ( Expr ) Expression blocks ( ExpressionBlock ) Accumulator ( Accumulator ) The parser first breaks source text into primitive blocks (1), then maps the internal language parser over a list of primitive blocks to produce expression blocks (3). Finally, the function transformAccumulate is mapped over the list of expression blocks, simultaneously collecting information such as cross-references and updating the list of expression blocks with that information","title":"Data Structures"},{"location":"dataStructures/#primitive-blocks","text":"Blocks have the rather elaborate type listed below. This complex structure is necessary for interactive real-time editing with error recovery. By real-time we mean that the rendered text is updated \"instantaneously\" in the browser as the user types in text. By interactive, we mean (for example) that click on the rendered text brings the associated source text into view while simultaneously highlighting it. In addition, if the user selects a block of source text and presses ctrl-S (S for 'sync'), the corresponding rendered text is brought into view and highlighted. In the case of L0 and XMarkdown, a primitive block is defined by -- Parser.PrimitiveBlock type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status .","title":"Primitive Blocks"},{"location":"dataStructures/#example-l0","text":"Consider the block | theorem (Magnus Axelsson) note:this is a joke temperature:22 If $a = b$ then $b = a$. There \"(Magnus Axelsson) note:this is a joke temperature:22\" is the argument string. This string is a sequences of words. Normal words do not contain the \":\" character. Words of the form a:b , where a is normal are key-value words, representing key-value pairs. Normal words must precede key-value words. The former make up the argument list, whereas the latter define the entries of the property dictionary. Thus we have args = [\"(Magnus\", \"Axellson)\"] properties = Dict.fromList [(\"note\", \"this is a joke\"), (\"temperature\", \"22\")] Arguments and properties are treated the same for verbatim blocks as for ordinary blocks.","title":"Example (L0)"},{"location":"dataStructures/#example-microlatex","text":"Below is a LaTeX environment with an LaTeX optional argument. In this case the args list is empty and their are three key-value pairs in the properties dictiononary \\begin{theorem}[foo:1, hoho:a b c, bar:2] If $a = b$ then $b = a$ \\end{theorem} args = [] properties = Dict.fromList [(\"bar\", \"2\"), (\"foo\", \"1\"), (\"hoho\", \"a b c\"] At the moment, environments with normal arguemnts are not handled, e.g., \\begin{theorem}{X}{Y}[foo:1, hoho:a b c, bar:2] If $a = b$ then $b = a$ \\end{theorem} This should produce args = [\"X\", \"Y\"]","title":"Example (MicroLaTeX)"},{"location":"dataStructures/#coercion-and-pseudoblocks","text":"Certain constructs such as \\image{https://yadayada.org/sparrow.jpg width:300} or \\item foo bar ... look to be syntactically part of the surface internal language of MicroLaTeX. However, in source text they alway appear with an empty line above and below and so are parsed as an anonymous (paragraph) block. They must be coerced into being an ordinary or verbatim block, e.g., { name = \"image\" , blockType = PBVerbatim , properties = Dict.fromList [(\"width\", \"200\")] , content = [\"image{https://yadayada.org/sparrow.jpg\"] ... } or { name = \"image\" , blockType = PBOrdinary , content = [\"foo bar ...\"] ... } This coercion is accomplished by functions in module MicroLaTeX.Parser.Transform , e.g., -- module MicroLaTeX.Parser.Transform handlePseudoBlockWithContent : String -> Maybe String -> PrimitiveBlock -> PrimitiveBlock handlePseudoBlockWithContent name maybeArg block = ... handleImage : PrimitiveBlock -> PrimitiveBlock The names of these elements must appear in the pseudoBlockNamesWithContent list: -- module MicroLaTeX.Parser.Transform pseudoBlockNamesWithContent = [ \"title\", \"section\", \"subsection\", \"subsubsection\" , \"subheading\", \"setcounter\", \"contents\", \"endnotes\", \"image\" ]","title":"Coercion and Pseudoblocks"},{"location":"dataStructures/#expressions","text":"-- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta","title":"Expressions"},{"location":"dataStructures/#expression-blocks","text":"-- Parser.Block type ExpressionBlock = ExpressionBlock { name : Maybe String , args : List String , properties : Dict String String , indent : Int , lineNumber : Int , numberOfLines : Int , id : String , tag : String , blockType : BlockType , content : Either String (List Expr) , messages : List String , sourceText : String , error : Maybe { error : String } }","title":"Expression Blocks"},{"location":"dataStructures/#edit-records","text":"Module: Compiler.AbstractDifferentialCompiler To manage differential compilation, one uses EditRecords . The main idea is to keep track of the current list of primitive blocks ( List chunk ) and the current parse structure ( tree ). When an edit is made, the source is parsed into primitive blocks and the new and old lists are compared, producing a diff record which shows which blocks have been changed. The changed blocks are parsed, then incorporated into the current list of expression blocks ( List parsedChunk ). type alias EditRecord chunk parsedChunk accumulator = { chunks : List chunk , parsed : List parsedChunk , tree : List (Tree parsedChunk) , accumulator : accumulator , lang : Language , messages : List String , initialData : InitialData } Orchestration of the process outlined above is conducted by the update function listed below. -- Compiler.AbstractDifferentialParser update : UpdateFunctions chunk parsedChunk acc -> String -> EditRecord chunk parsedChunk acc -> EditRecord chunk parsedChunk acc The first argument is a record that holds the functions needed in any concrete instantiation of the update function, e.g, the field setLineNumber : Int -> parsedChunk -> parsedChunk used in renumbering parsed chunks. XX: more on keeping the line numbers up-to-data.","title":"Edit records"},{"location":"dataStructures/#diff-records","text":"Module: Compiler.Differ Let u and v be two lists of things of type p . Write them as u = axb, v = ayb, where a is the greatest common prefix and b is the greatest common suffix. Return DiffRecord a b x y. The type parameter can be anything: characters, strings, primitive blocks, etc. In the example below, p = Char . type alias DiffRecord p = { commonPrefix : List p , commonSuffix : List p , middleSegmentInSource : List p , middleSegmentInTarget : List p } Example > import Compiler.Differ exposing(..) > a = \"abcxyzdef\" |> String.split \"\" [\"a\",\"b\",\"c\",\"x\",\"y\",\"z\",\"d\",\"e\",\"f\"] : List String > b = \"abcXYZdef\" |> String.split \"\" [\"a\",\"b\",\"c\",\"X\",\"Y\",\"Z\",\"d\",\"e\",\"f\"] : List String > diff a b { commonPrefix = [\"a\",\"b\",\"c\"] , commonSuffix = [\"d\",\"e\",\"f\"], , middleSegmentInSource = [\"x\",\"y\",\"z\"] , middleSegmentInTarget = [\"X\",\"Y\",\"Z\"] }","title":"Diff Records"},{"location":"dataStructures/#diffing-a-forest","text":"Module: Compiler.DifferForest The diff function in this module is designed to diff lists with an implicit forest structure (list of trees) defined by a function level: p -> Int . In the resulting DiffRecord , the prefix, suffix, and middle segments all represent subforests. The diff function in this module is used to diff primitive blocks in the compiler. diff : (p -> p -> Bool) -> (p -> Int) -> List p -> List p -> DiffRecord p diff eq level u v = The function eq: p -> p -> Bool tests for equality ... XX: more detail. In the case of primitive blocks ... important that line numbers be properly computed in the common suffix ... To illustrate the main issue, consider the lists u and v (below). These have an indentation structure like an outline for an article, and so define the structure of a forest. In the example below, the leaf jkl in the tree with root def is changed to JKL . u: ---- abc def ghi jkl mno pqr v: ---- abc def ghi JKL mno pqr In this example the diff record represents the following structure: commonPrefix: ---- abc middleSegmentInSource: --- def ghi jkl mno middleSegmentInTarget: --- def ghi JKL mno commonSuffix: --- pqr XX, Expand on this, explain it: -- IMPORTANT: taking y from v, the second argument -- ensures that the line numbers in the common suffix -- are correct","title":"Diffing a Forest"},{"location":"dataStructures/#accumulator","text":"Module: Compiler.Acc The Accumulator type is used to collect, build up, and apply auxiliary information about the text. For example, the headingIndex stores the current section number, where \"current\" refers to the the current section of the document as the accumulator-building function walks through the current parse forest. As it does, it simultaneously (1) updates the accumulator and (2) applies new \"patches\" of the accumulator to the parse forest. This process is managed by function transformAccumulateTree which is called every time the parser pipeline runs. For this reason one does not have to recompile to have up-to-date cross-references, etc., as in standard LaTeX. transformAccumulate : InitialAccumulatorData -> Forest ExpressionBlock -> ( Accumulator, Forest ExpressionBlock ) Type definition: -- Compiler.Acc type alias Accumulator = { language : Language , headingIndex : Vector , documentIndex : Vector , counter : Dict String Int , blockCounter : Int , itemVector : Vector -- Used for section numbering , numberedItemDict : Dict String { level : Int, index : Int } , numberedBlockNames : List String , inList : Bool , reference : Dict String { id : String, numRef : String } , terms : Dict String TermLoc , footnotes : Dict String TermLoc , footnoteNumbers : Dict String Int , mathMacroDict : Parser.MathMacro.MathMacroDict , textMacroDict : Dict String Macro , keyValueDict : Dict String String , qAndAList : List ( String, String ) , qAndADict : Dict String String }","title":"Accumulator"},{"location":"differential-compiler/","text":"Differential Compilation Differential compilation is an optimization used to speed up recompilation of large inputs. Since parsing is the most expensive part of the compiler pipeline, the idea is to only re-parse what has been changed after an edit. Differ We use an extremely primitive strategy. Let u and v be two lists of things of type p . Write them as u = axb, v = ayb, where a is the greatest common prefix and b is the greatest common suffix. Return DiffRecord a b x y. This operation is carried out by -- Compiler.Differ diff : List p -> List p -> DiffRecord p where -- Compiler.Differ type alias DiffRecord p = { commonPrefix : List p , commonSuffix : List p , middleSegmentInSource : List p , middleSegmentInTarget : List p } A DiffRecord can be used to transform a list using function differentialTransform and a function transform: p -> q . -- Compiler.Differ differentialTransform : (p -> q) -> DiffRecord p -> List q -> List q DifferForest Module Compiler.DifferForest is designed to diff lists with an implicit forest structure (list of trees) defined by a function level: p -> Int . In the resulting DiffRecord , the prefix, suffix, and middle segments all represent subforests. To illustrate the main issue, consider the lists u and v (below). These have an indentation structure like an outline for an article, and so define the structure of a forest. Here the leaf jkl in the tree with root def is changed to JKL . u: ---- abc def ghi jkl mno pqr v: ---- abc def ghi JKL mno pqr The resuting diff record represents the following structure: commonPrefix: ---- abc middleSegmentInSource: --- def ghi jkl mno middleSegmentInTarget: --- def ghi JKL mno commonSuffix: --- pqr Abstract Differential Parser diffRecord.commonPrefix ++ diffRecord.middleSegmentInTarget ++ diffRecord.commonSuffix Differential Parsing in Scripta In Scripta, differential parsing takes place at the level of primitive blocks, as indicated in the flowchart .","title":"Differential Compilation"},{"location":"differential-compiler/#differential-compilation","text":"Differential compilation is an optimization used to speed up recompilation of large inputs. Since parsing is the most expensive part of the compiler pipeline, the idea is to only re-parse what has been changed after an edit.","title":"Differential Compilation"},{"location":"differential-compiler/#differ","text":"We use an extremely primitive strategy. Let u and v be two lists of things of type p . Write them as u = axb, v = ayb, where a is the greatest common prefix and b is the greatest common suffix. Return DiffRecord a b x y. This operation is carried out by -- Compiler.Differ diff : List p -> List p -> DiffRecord p where -- Compiler.Differ type alias DiffRecord p = { commonPrefix : List p , commonSuffix : List p , middleSegmentInSource : List p , middleSegmentInTarget : List p } A DiffRecord can be used to transform a list using function differentialTransform and a function transform: p -> q . -- Compiler.Differ differentialTransform : (p -> q) -> DiffRecord p -> List q -> List q","title":"Differ"},{"location":"differential-compiler/#differforest","text":"Module Compiler.DifferForest is designed to diff lists with an implicit forest structure (list of trees) defined by a function level: p -> Int . In the resulting DiffRecord , the prefix, suffix, and middle segments all represent subforests. To illustrate the main issue, consider the lists u and v (below). These have an indentation structure like an outline for an article, and so define the structure of a forest. Here the leaf jkl in the tree with root def is changed to JKL . u: ---- abc def ghi jkl mno pqr v: ---- abc def ghi JKL mno pqr The resuting diff record represents the following structure: commonPrefix: ---- abc middleSegmentInSource: --- def ghi jkl mno middleSegmentInTarget: --- def ghi JKL mno commonSuffix: --- pqr","title":"DifferForest"},{"location":"differential-compiler/#abstract-differential-parser","text":"diffRecord.commonPrefix ++ diffRecord.middleSegmentInTarget ++ diffRecord.commonSuffix","title":"Abstract Differential Parser"},{"location":"differential-compiler/#differential-parsing-in-scripta","text":"In Scripta, differential parsing takes place at the level of primitive blocks, as indicated in the flowchart .","title":"Differential Parsing in Scripta"},{"location":"introduction/","text":"Introduction The Scripta compiler translates source text written in a markup language to an Elm representation of Html. Markup Languages The languages supported by Scripta are L0 microLaTeX XMarkdown Blocks The text of these markup languages should be thought of as structured into blocks, the content of which is written in an internal language . For example, in microLaTeX, one might have the text below. There are seven blocks, each of which is separated from its neighbor by an empty line. The first block is a paragraph; its content consists of plain text followed by the TeX macro expression \\italic{prime} followed by more plain text. Let's talk about \\italic{prime} numbers. \\begin{theorem} There are infinitely many primes $p$, and in fact there are infinitely many primes \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 4 \\end{equation} and also \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 8 \\end{equation} and so on. \\end{theorem} The first paragraph of the theorem was known to Euclid. The body of the theorem block consists of six blocks \u2014 the three paragraph blocks Let's talk ... , and also , and and so on . There also the two equation blocks. The blocks in the body of the theorem block constitute the \\italic{children} of the block. It is the job of the parser to (1) discover the forest structure, and (2) to parse the content of the blocks. Note that we can visualize the block structure as an outline, as below. PARAGRAPH THEOREM PARAGRPH EQUATION EQUATION PARAGRAPH PARAGRAM In some languages, e.g. L0 and Markdown, the block structure is literally given by the \"outline\" structure, that is, by indentation. Below is our example rewritten in L0: Let's talk about [italic prime] numbers. | theorem There are infinitely many primes $p$, and in fact there are infinitely many primes || equation p \\equiv 1 \\ \\text{mod}\\ 4 and also || equation p \\equiv 1 \\ \\text{mod}\\ 8 and so on. The first paragraph of the theorem was known to Euclid. Note that an outline is fully equivalent to a tree: |-- PARAGRAPH |-- THEOREM |- PARAGRAPH |- EQUATION |- EQUATION |- PARAGRAPH |- PARAGRAPH Internal Language While the surface syntax in L0, microLaTeX and XMarkdown depends on the language, the abstract syntax is the same for all tree. Indeed, text in the internal language always parses to Either String (List Expr) , where type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta Block Definition In the case of L0 and XMarkdown, a primitive block is defined by type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status .","title":"Introduction"},{"location":"introduction/#introduction","text":"The Scripta compiler translates source text written in a markup language to an Elm representation of Html.","title":"Introduction"},{"location":"introduction/#markup-languages","text":"The languages supported by Scripta are L0 microLaTeX XMarkdown","title":"Markup Languages"},{"location":"introduction/#blocks","text":"The text of these markup languages should be thought of as structured into blocks, the content of which is written in an internal language . For example, in microLaTeX, one might have the text below. There are seven blocks, each of which is separated from its neighbor by an empty line. The first block is a paragraph; its content consists of plain text followed by the TeX macro expression \\italic{prime} followed by more plain text. Let's talk about \\italic{prime} numbers. \\begin{theorem} There are infinitely many primes $p$, and in fact there are infinitely many primes \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 4 \\end{equation} and also \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 8 \\end{equation} and so on. \\end{theorem} The first paragraph of the theorem was known to Euclid. The body of the theorem block consists of six blocks \u2014 the three paragraph blocks Let's talk ... , and also , and and so on . There also the two equation blocks. The blocks in the body of the theorem block constitute the \\italic{children} of the block. It is the job of the parser to (1) discover the forest structure, and (2) to parse the content of the blocks. Note that we can visualize the block structure as an outline, as below. PARAGRAPH THEOREM PARAGRPH EQUATION EQUATION PARAGRAPH PARAGRAM In some languages, e.g. L0 and Markdown, the block structure is literally given by the \"outline\" structure, that is, by indentation. Below is our example rewritten in L0: Let's talk about [italic prime] numbers. | theorem There are infinitely many primes $p$, and in fact there are infinitely many primes || equation p \\equiv 1 \\ \\text{mod}\\ 4 and also || equation p \\equiv 1 \\ \\text{mod}\\ 8 and so on. The first paragraph of the theorem was known to Euclid. Note that an outline is fully equivalent to a tree: |-- PARAGRAPH |-- THEOREM |- PARAGRAPH |- EQUATION |- EQUATION |- PARAGRAPH |- PARAGRAPH","title":"Blocks"},{"location":"introduction/#internal-language","text":"While the surface syntax in L0, microLaTeX and XMarkdown depends on the language, the abstract syntax is the same for all tree. Indeed, text in the internal language always parses to Either String (List Expr) , where type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta","title":"Internal Language"},{"location":"introduction/#block-definition","text":"In the case of L0 and XMarkdown, a primitive block is defined by type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status .","title":"Block Definition"},{"location":"l0/","text":"L0 (( Under construction! )) Parsing Expresssions Recall that we use the same type for L0 expressions as we do for MicroLaTeX and XMarkdown: -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta The parser for expressions uses the shift-reduce strategy and is implemented as a functional loop with state where the state is given by -- L0.Parser.Expression type alias State = { step : Int , tokens : List Token , numberOfTokens : Int , tokenIndex : Int , committed : List Expr , stack : List Token , messages : List String , lineNumber : Int } with driving function State -> Step State State defined by -- L0.Parser.Expression nextStep : State -> Step State State nextStep state = case getToken state of Nothing -> if stackIsEmpty state then Done state else recoverFromError state Just token -> state |> advanceTokenIndex |> pushOrCommit token |> reduceState |> (\\st -> { st | step = st.step + 1 }) |> Loop The reduceState function asks whether the stack is reducible using the function isReducible discussed below. If it is, it reduces the stack using reduceStack , returning the updated state. If not, the state is passed on unchanged. -- L0.Parser.Expression reduceState : State -> State reduceState state = if tokensAreReducible state then { state | stack = [], committed = reduceStack state ++ state.committed } else state Reducibility -- L0.Parser.Match: isReducible : List Symbol -> Bool isReducible symbols_ = let symbols = List.filter (\\sym -> sym /= WS) symbols_ in case symbols of M :: rest -> List.head (List.reverse rest) == Just M C :: rest -> List.head (List.reverse rest) == Just C L :: ST :: rest -> case List.head (List.reverse rest) of Just R -> hasReducibleArgs (dropLast rest) _ -> False _ -> False","title":"L0"},{"location":"l0/#l0","text":"(( Under construction! ))","title":"L0"},{"location":"l0/#parsing-expresssions","text":"Recall that we use the same type for L0 expressions as we do for MicroLaTeX and XMarkdown: -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta The parser for expressions uses the shift-reduce strategy and is implemented as a functional loop with state where the state is given by -- L0.Parser.Expression type alias State = { step : Int , tokens : List Token , numberOfTokens : Int , tokenIndex : Int , committed : List Expr , stack : List Token , messages : List String , lineNumber : Int } with driving function State -> Step State State defined by -- L0.Parser.Expression nextStep : State -> Step State State nextStep state = case getToken state of Nothing -> if stackIsEmpty state then Done state else recoverFromError state Just token -> state |> advanceTokenIndex |> pushOrCommit token |> reduceState |> (\\st -> { st | step = st.step + 1 }) |> Loop The reduceState function asks whether the stack is reducible using the function isReducible discussed below. If it is, it reduces the stack using reduceStack , returning the updated state. If not, the state is passed on unchanged. -- L0.Parser.Expression reduceState : State -> State reduceState state = if tokensAreReducible state then { state | stack = [], committed = reduceStack state ++ state.committed } else state","title":"Parsing Expresssions"},{"location":"l0/#reducibility","text":"-- L0.Parser.Match: isReducible : List Symbol -> Bool isReducible symbols_ = let symbols = List.filter (\\sym -> sym /= WS) symbols_ in case symbols of M :: rest -> List.head (List.reverse rest) == Just M C :: rest -> List.head (List.reverse rest) == Just C L :: ST :: rest -> case List.head (List.reverse rest) of Just R -> hasReducibleArgs (dropLast rest) _ -> False _ -> False","title":"Reducibility"},{"location":"lx/","text":"MicroLaTeX The MicroLaTeX parser first transforms source into a list of primitive LaTeX blocks using a shift-reduce parser with error recovery . It then maps the parser for the internal language over this list, into a list of expression blocks. Data Structures Primitive Blocks A primitve LaTeX block is a 13-field record as displayed below. -- Parser.PrimitiveLaTeXBlock type alias PrimitiveLaTeXBlock = { indent : Int , lineNumber : Int , position : Int , level : Int , content : List String , firstLine : String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , status : Status , error : Maybe PrimitiveBlockError } When the source text is parsed into a list of blocks, it is grouped into lists of strings in the content field. The content is also stored as a string in the sourceText field. This is to facilitate synchronization of source text and rendered text. The source text field is carried into the final syntax tree (forest of expression blocks). Consequently, if a piece source text is selected, the syntax tree can can be searched, the matching element can be located and then used to highlight the corresponding part of the rendered text. The indent field is the number of spaces of indentation of the first line of the block; lineNumber is the line number of the first line of the text in the source string; position is its character position in that string. The level field is the depth of the block in the eventual tree structure. Blocks may be un-named, as in the case of paragraph, or named, in the case of a LaTeX environment. This information is stored in the name field. For example, the name of the block \\begin{theorem} ... \\end{theorem} is Just \"theorem\" The firstline field is the first line of a block, i.e., its header. If the header of a block is \"\\begin{theorem}[Pythagoras]\", then its name is \"theorem\" and args is the list [\"Pythagoras] . If we had \"\\begin{theorem}[Pythagoras, foo:bar]\" (XX) then args is still [\"Pythagoras\"], and properties is a dictionary with one key, \"foo\", whose value is \"bar\". Thus args is a list of unnamed args and properties is a dictionary of key-value pairs derived from the named args. (XX: improve this discussion) The blockType field has type type PrimitiveBlockType = PBVerbatim | PBOrdinary | PBParagraph It describes the type of block \u2014 unnamed, environment like \"theorem\" in which the body of the block is parsed, or environment like \"equation\" where it is passed verbatim to the renderer. The status field has type type Status = Finished | Started | Filled It is used by the primitive block parser and is needed to handle nested blocks. Primitive Block Parser The parser is defined in module Parser.PrimitiveLaTeXBlock . Lists of lines of text are parsed into lists of primitive blocks by the function -- Parser.PrimitiveLaTeXBlock parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks The strategy is to examine each line in turn, committing the current block if its mathching end tag is found, otherwise pushing it onto a stack of blocks. All blocks are moved from the stack to the committed list when the \"root\" or first block on the stack as well as all of its children are closed. If the stack is nonempty after all blocks have been consumed, there has been a syntax error, and so the error recovery procedure is invoked. Data structure -- Parser.PrimtiiveLaTeXBlock -- 14 fields type alias State = { blocks : List PrimitiveLaTeXBlock , stack : List PrimitiveLaTeXBlock , holdingStack : List PrimitiveLaTeXBlock , labelStack : List Label , lines : List String , sourceText : String , firstBlockLine : Int , indent : Int , level : Int , lineNumber : Int , position : Int , verbatimClassifier : Maybe Classification , count : Int , label : String } where type alias Label = { classification : ClassifyBlock.Classification , level : Int , status : Status , lineNumber : Int } The blocks field holds the committed blocks \u2014 the eventual output of the parser. The stack field holds Main parsing functions parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks and parseLoop : List String -> ParserOutput parseLoop lines = loop (init lines) nextStep |> finalize where type alias ParserOutput = { blocks : List PrimitiveLaTeXBlock , stack : List PrimitiveLaTeXBlock , holdingStack : List PrimitiveLaTeXBlock } The nextStep function This is the driver function for the parser's functional loop . It operates as follows: - Increment state.lineNumber. - If the input (state.lines) has been consumed and - the stack is empty, return Done state - the stack is non empty, return recoverFromError state - Let the current raw line be the string at index state.lineNumber of state.lines. - Classify the raw line, a value of type Classification: type Classification = CBeginBlock String | CEndBlock String | CSpecialBlock LXSpecial | CMathBlockDelim | CVerbatimBlockDelim | CPlainText | CEmpty - Invoke a handler based on the classification that returns a value of type Step State State New blocks are constructed by nextStep using blockFromLine : Int -> Line -> PrimitiveLaTeXBlock The primitive block type ( PBVerbatim , PBOrdinary , PBParagraph ) and the label (in the case of the first two variants) is determined by examining the contents of the line. For example, if the line is \"\\begin{equation}\" then the primitive block type is PBVerbatim and the label is \"equation\" . The label is used to run the parser loop; when a block is committed, the label is used to form the name: Maybe String field of the primitive block. This field is Nothing in the case of PBParagraph and is a Just String in the case of the other two block types. Error recovery Recall that error recovery is invoked when the stack is nonempty after all input has been consumed. The recovery strategy is to commit the root block on the stack, setting the error field to missingTagError block , then reparse the input starting from the line immediately after that of the offending block. Consequently error recovery is guaranteed to terminate and also to deal with additional errors. Error recovery is handled by recoverFromError : State -> State Transform Module MicroLaTeX.Parser.Transform The purpose of this function is to transform a primitive block like the one coming from a single-line paragraph with text \"\\section{Intro}\" to an ordinary (blockType PBOrdinaryBlock) block with name \"section\", args [\"1\"], and content [\"Introduction\"]. This is to coerce parsed MiniLaTeX source to our standard model. Verbatim Blocks If a block is to be treated as a verbatim block, its name must appear in Parser.LaTeXBlock.verbatimBlockNames : List String Note. What's the deal with Parser.Common.verbatimBlockNames ? verbatimBlockNames = [ \"equation\" , \"aligned\" , \"math\" , \"code\" , \"verbatim\" , \"verse\" , \"mathmacros\" , \"textmacros\" , \"tabular\" , \"hide\" , \"docinfo\" , \"datatable\" , \"chart\" , \"svg\" , \"quiver\" , \"image\" , \"tikz\" , \"load-files\" , \"include\" , \"iframe\" ] Tests Test parsing of text to a list of primitive blocks: -- MicroLaTeXParserTest primitiveBlockRoundTripTest \"nested environments\" text1 Test the internal language: -- MicroLaTeXParserTest roundTrip1 \"\\\\blue{\\\\italic{abc \\\\strong{def}}}\" Test coercion of MicroLaTeX macros to blocks: -- TransformLaTeXTest test_ \"tags\" (toL0 [ \"\\\\tags{AAA}\" ]) [ \"| tags AAA \" ] -- TransformTest test_ \"transform, args\" (toPrimitiveBlocks \"\\n\\n\\\\section{Intro}\\n\\n\" |> List.map transform |> List.map .args) [ [ \"1\" ] ] where toPrimitiveBlocks = Markup.toPrimitiveBlocks MicroLaTeXLang Command line tools The ./CLI folder contains various CLI tools for testing and benchmarking. All use Albert Dahlin's elm/posix package and can be run using velociraptor (command: vr ). Some examples: vr lxpb lxtest/a1.txt vr rt foo.txt vr bench init 100 bench/harmonic.tex","title":"MicroLaTeX"},{"location":"lx/#microlatex","text":"The MicroLaTeX parser first transforms source into a list of primitive LaTeX blocks using a shift-reduce parser with error recovery . It then maps the parser for the internal language over this list, into a list of expression blocks.","title":"MicroLaTeX"},{"location":"lx/#data-structures","text":"","title":"Data Structures"},{"location":"lx/#primitive-blocks","text":"A primitve LaTeX block is a 13-field record as displayed below. -- Parser.PrimitiveLaTeXBlock type alias PrimitiveLaTeXBlock = { indent : Int , lineNumber : Int , position : Int , level : Int , content : List String , firstLine : String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , status : Status , error : Maybe PrimitiveBlockError } When the source text is parsed into a list of blocks, it is grouped into lists of strings in the content field. The content is also stored as a string in the sourceText field. This is to facilitate synchronization of source text and rendered text. The source text field is carried into the final syntax tree (forest of expression blocks). Consequently, if a piece source text is selected, the syntax tree can can be searched, the matching element can be located and then used to highlight the corresponding part of the rendered text. The indent field is the number of spaces of indentation of the first line of the block; lineNumber is the line number of the first line of the text in the source string; position is its character position in that string. The level field is the depth of the block in the eventual tree structure. Blocks may be un-named, as in the case of paragraph, or named, in the case of a LaTeX environment. This information is stored in the name field. For example, the name of the block \\begin{theorem} ... \\end{theorem} is Just \"theorem\" The firstline field is the first line of a block, i.e., its header. If the header of a block is \"\\begin{theorem}[Pythagoras]\", then its name is \"theorem\" and args is the list [\"Pythagoras] . If we had \"\\begin{theorem}[Pythagoras, foo:bar]\" (XX) then args is still [\"Pythagoras\"], and properties is a dictionary with one key, \"foo\", whose value is \"bar\". Thus args is a list of unnamed args and properties is a dictionary of key-value pairs derived from the named args. (XX: improve this discussion) The blockType field has type type PrimitiveBlockType = PBVerbatim | PBOrdinary | PBParagraph It describes the type of block \u2014 unnamed, environment like \"theorem\" in which the body of the block is parsed, or environment like \"equation\" where it is passed verbatim to the renderer. The status field has type type Status = Finished | Started | Filled It is used by the primitive block parser and is needed to handle nested blocks.","title":"Primitive Blocks"},{"location":"lx/#primitive-block-parser","text":"The parser is defined in module Parser.PrimitiveLaTeXBlock . Lists of lines of text are parsed into lists of primitive blocks by the function -- Parser.PrimitiveLaTeXBlock parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks The strategy is to examine each line in turn, committing the current block if its mathching end tag is found, otherwise pushing it onto a stack of blocks. All blocks are moved from the stack to the committed list when the \"root\" or first block on the stack as well as all of its children are closed. If the stack is nonempty after all blocks have been consumed, there has been a syntax error, and so the error recovery procedure is invoked.","title":"Primitive Block Parser"},{"location":"lx/#data-structure","text":"-- Parser.PrimtiiveLaTeXBlock -- 14 fields type alias State = { blocks : List PrimitiveLaTeXBlock , stack : List PrimitiveLaTeXBlock , holdingStack : List PrimitiveLaTeXBlock , labelStack : List Label , lines : List String , sourceText : String , firstBlockLine : Int , indent : Int , level : Int , lineNumber : Int , position : Int , verbatimClassifier : Maybe Classification , count : Int , label : String } where type alias Label = { classification : ClassifyBlock.Classification , level : Int , status : Status , lineNumber : Int } The blocks field holds the committed blocks \u2014 the eventual output of the parser. The stack field holds","title":"Data structure"},{"location":"lx/#main-parsing-functions","text":"parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks and parseLoop : List String -> ParserOutput parseLoop lines = loop (init lines) nextStep |> finalize where type alias ParserOutput = { blocks : List PrimitiveLaTeXBlock , stack : List PrimitiveLaTeXBlock , holdingStack : List PrimitiveLaTeXBlock }","title":"Main parsing functions"},{"location":"lx/#the-nextstep-function","text":"This is the driver function for the parser's functional loop . It operates as follows: - Increment state.lineNumber. - If the input (state.lines) has been consumed and - the stack is empty, return Done state - the stack is non empty, return recoverFromError state - Let the current raw line be the string at index state.lineNumber of state.lines. - Classify the raw line, a value of type Classification: type Classification = CBeginBlock String | CEndBlock String | CSpecialBlock LXSpecial | CMathBlockDelim | CVerbatimBlockDelim | CPlainText | CEmpty - Invoke a handler based on the classification that returns a value of type Step State State New blocks are constructed by nextStep using blockFromLine : Int -> Line -> PrimitiveLaTeXBlock The primitive block type ( PBVerbatim , PBOrdinary , PBParagraph ) and the label (in the case of the first two variants) is determined by examining the contents of the line. For example, if the line is \"\\begin{equation}\" then the primitive block type is PBVerbatim and the label is \"equation\" . The label is used to run the parser loop; when a block is committed, the label is used to form the name: Maybe String field of the primitive block. This field is Nothing in the case of PBParagraph and is a Just String in the case of the other two block types.","title":"The nextStep function"},{"location":"lx/#error-recovery","text":"Recall that error recovery is invoked when the stack is nonempty after all input has been consumed. The recovery strategy is to commit the root block on the stack, setting the error field to missingTagError block , then reparse the input starting from the line immediately after that of the offending block. Consequently error recovery is guaranteed to terminate and also to deal with additional errors. Error recovery is handled by recoverFromError : State -> State","title":"Error recovery"},{"location":"lx/#transform","text":"Module MicroLaTeX.Parser.Transform The purpose of this function is to transform a primitive block like the one coming from a single-line paragraph with text \"\\section{Intro}\" to an ordinary (blockType PBOrdinaryBlock) block with name \"section\", args [\"1\"], and content [\"Introduction\"]. This is to coerce parsed MiniLaTeX source to our standard model.","title":"Transform"},{"location":"lx/#verbatim-blocks","text":"If a block is to be treated as a verbatim block, its name must appear in Parser.LaTeXBlock.verbatimBlockNames : List String Note. What's the deal with Parser.Common.verbatimBlockNames ? verbatimBlockNames = [ \"equation\" , \"aligned\" , \"math\" , \"code\" , \"verbatim\" , \"verse\" , \"mathmacros\" , \"textmacros\" , \"tabular\" , \"hide\" , \"docinfo\" , \"datatable\" , \"chart\" , \"svg\" , \"quiver\" , \"image\" , \"tikz\" , \"load-files\" , \"include\" , \"iframe\" ]","title":"Verbatim Blocks"},{"location":"lx/#tests","text":"Test parsing of text to a list of primitive blocks: -- MicroLaTeXParserTest primitiveBlockRoundTripTest \"nested environments\" text1 Test the internal language: -- MicroLaTeXParserTest roundTrip1 \"\\\\blue{\\\\italic{abc \\\\strong{def}}}\" Test coercion of MicroLaTeX macros to blocks: -- TransformLaTeXTest test_ \"tags\" (toL0 [ \"\\\\tags{AAA}\" ]) [ \"| tags AAA \" ] -- TransformTest test_ \"transform, args\" (toPrimitiveBlocks \"\\n\\n\\\\section{Intro}\\n\\n\" |> List.map transform |> List.map .args) [ [ \"1\" ] ] where toPrimitiveBlocks = Markup.toPrimitiveBlocks MicroLaTeXLang","title":"Tests"},{"location":"lx/#command-line-tools","text":"The ./CLI folder contains various CLI tools for testing and benchmarking. All use Albert Dahlin's elm/posix package and can be run using velociraptor (command: vr ). Some examples: vr lxpb lxtest/a1.txt vr rt foo.txt vr bench init 100 bench/harmonic.tex","title":"Command line tools"},{"location":"mkdocs/","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"mkdocs/#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"mkdocs/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"mkdocs/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"overview/","text":"Overview The Scripta compiler transforms text into Element Msg through a series of stages, as illustrated in the following figure. Break the source text into chunks , namely a list of so-called primitive blocks . Ignoring for the moment the possibility of diff records and differential compilation, parse the content of the primitive blocks, transforming string data into lists of Expr (see Intro, section \"Internal Language\" ) Transform the list of expression blocks into a forest of expression blocks using the indentation structure or, in the case of microLaTeX, the level structure. Walk through the forest of expression blocks, accumulating data on section numbers, the table of contents, cross-references etc, while simultaneously updating the forest of expression blocks where indicated. Use this data to produce a so-called EditRecord , a data structure containing all the information needed to render the original source text into Element MarkupMsg , an Elm representation of Html. Use the Edit Record to produce the final rendered text. Flowchart Parsing the internal language Let us concentrate for the moment on step (2) above, parsing the content of the primitive blocks. We will do this first in the case of \"pure\" L0, a simplified version of L0 described below. All the ideas needed in the general case, including for microLaTeX and XMarkdown are present in this simple case. The parser first tokenizes the input, then consumes the tokens one at a time. To process them, it maintains two data structures: a list of committed expressions and a stack of \"unreduced\" tokens. At each step the parser may either commit the token or push it onto the stack. The stack contents may or may not be reducible to an expression (see XX below for examples). If the stack is reducible, the resulting expression is pushed onto the committed list. If not, the process continues. If the stack is empty after all the tokens have been consumed, the parse is successful. If not, there is an error, and the recovery procedure is called. In rough outline, the procedure is as follows: (a) remove the token at the bottom of the stack and use it to construct an expression indicating the presence and nature of the error; (b) push this expression onto the committed list; (c) restart the parser with the truncated stack as input. In short, error recovery works by pushing an error expression onto the committed list based the state of the stack, then skipping a token and restarting the parser. This procedure is guaranteed to terminate and can also handle multiple errors. Whiile simple, it has proved effective in the case of the three markup languages considered here. The strategy just described is essentially that of a classical shift-reduce parser. The shift operation is the act of taking a token from the input and putting it either on the stack or (as an expression), the committed list. The reduce operation occurs when the stack represents an expression: that expression is pushed onto the committed list and the stack is cleared. Pure L0 An element of pure L0 text is one of the following: a span of pure text, e.g. \"roses are red\" a function element, e.g. [italic roses are red] , consisting of a function name (italic here) and a body, which is a sequence consisting of pure text spans and function elements. a sequence of the above. Function elements can be nested, as in [italic roses [bold are] red \". In this example, \"roses\" and \"red\" are italicized, while \"are\" bold italic. Here is a slightly more complicated example: He said that [italic roses [bold are] red]. Cool! Tokenization Tokens for pure L0 are of the type listed below. The constructors LB and RB refer to left and right brackets. Meta is a meta data field that records the location of the part of the source text corresponding to the token. S stands for String and W stands for white space. type Token = LB Meta | RB Meta | S String Meta As an example, the text \"[italic roses]\" tokenizes as LB, S \"italic\", S \" roses\", RB where we have ignored the Meta component. You can verify this as follows: $ elm repl > import L0.Parser.Token exposing(..) > run \"[italic roses]\" |> List.reverse The second token in full form is S \"italic\" { begin = 1, end = 6, index = 1 } The index refers to the index of the token in the token list. It will be used in error recovery. Reduction of a list of tokens Recall that expressions are of type -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta The token list LB, S \"italic\", S \" roses\", RB represents an expression, namely Fun \"italic\" [S \" roses\"] where again we ignore the metadata. On the other hand, the token list LB, S \"italic\", S \" roses\" is not reducible, since the opening LB is unmatched. See the detailed documentation of the L0 parser to see how the function isReducible : List Symbol -> Bool works.","title":"Overview"},{"location":"overview/#overview","text":"The Scripta compiler transforms text into Element Msg through a series of stages, as illustrated in the following figure. Break the source text into chunks , namely a list of so-called primitive blocks . Ignoring for the moment the possibility of diff records and differential compilation, parse the content of the primitive blocks, transforming string data into lists of Expr (see Intro, section \"Internal Language\" ) Transform the list of expression blocks into a forest of expression blocks using the indentation structure or, in the case of microLaTeX, the level structure. Walk through the forest of expression blocks, accumulating data on section numbers, the table of contents, cross-references etc, while simultaneously updating the forest of expression blocks where indicated. Use this data to produce a so-called EditRecord , a data structure containing all the information needed to render the original source text into Element MarkupMsg , an Elm representation of Html. Use the Edit Record to produce the final rendered text.","title":"Overview"},{"location":"overview/#flowchart","text":"","title":"Flowchart"},{"location":"overview/#parsing-the-internal-language","text":"Let us concentrate for the moment on step (2) above, parsing the content of the primitive blocks. We will do this first in the case of \"pure\" L0, a simplified version of L0 described below. All the ideas needed in the general case, including for microLaTeX and XMarkdown are present in this simple case. The parser first tokenizes the input, then consumes the tokens one at a time. To process them, it maintains two data structures: a list of committed expressions and a stack of \"unreduced\" tokens. At each step the parser may either commit the token or push it onto the stack. The stack contents may or may not be reducible to an expression (see XX below for examples). If the stack is reducible, the resulting expression is pushed onto the committed list. If not, the process continues. If the stack is empty after all the tokens have been consumed, the parse is successful. If not, there is an error, and the recovery procedure is called. In rough outline, the procedure is as follows: (a) remove the token at the bottom of the stack and use it to construct an expression indicating the presence and nature of the error; (b) push this expression onto the committed list; (c) restart the parser with the truncated stack as input. In short, error recovery works by pushing an error expression onto the committed list based the state of the stack, then skipping a token and restarting the parser. This procedure is guaranteed to terminate and can also handle multiple errors. Whiile simple, it has proved effective in the case of the three markup languages considered here. The strategy just described is essentially that of a classical shift-reduce parser. The shift operation is the act of taking a token from the input and putting it either on the stack or (as an expression), the committed list. The reduce operation occurs when the stack represents an expression: that expression is pushed onto the committed list and the stack is cleared.","title":"Parsing the internal language"},{"location":"overview/#pure-l0","text":"An element of pure L0 text is one of the following: a span of pure text, e.g. \"roses are red\" a function element, e.g. [italic roses are red] , consisting of a function name (italic here) and a body, which is a sequence consisting of pure text spans and function elements. a sequence of the above. Function elements can be nested, as in [italic roses [bold are] red \". In this example, \"roses\" and \"red\" are italicized, while \"are\" bold italic. Here is a slightly more complicated example: He said that [italic roses [bold are] red]. Cool!","title":"Pure L0"},{"location":"overview/#tokenization","text":"Tokens for pure L0 are of the type listed below. The constructors LB and RB refer to left and right brackets. Meta is a meta data field that records the location of the part of the source text corresponding to the token. S stands for String and W stands for white space. type Token = LB Meta | RB Meta | S String Meta As an example, the text \"[italic roses]\" tokenizes as LB, S \"italic\", S \" roses\", RB where we have ignored the Meta component. You can verify this as follows: $ elm repl > import L0.Parser.Token exposing(..) > run \"[italic roses]\" |> List.reverse The second token in full form is S \"italic\" { begin = 1, end = 6, index = 1 } The index refers to the index of the token in the token list. It will be used in error recovery.","title":"Tokenization"},{"location":"overview/#reduction-of-a-list-of-tokens","text":"Recall that expressions are of type -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta The token list LB, S \"italic\", S \" roses\", RB represents an expression, namely Fun \"italic\" [S \" roses\"] where again we ignore the metadata. On the other hand, the token list LB, S \"italic\", S \" roses\" is not reducible, since the opening LB is unmatched. See the detailed documentation of the L0 parser to see how the function isReducible : List Symbol -> Bool works.","title":"Reduction of a list of tokens"},{"location":"render/","text":"Rendering render : Int -> Accumulator -> Settings -> ExpressionBlock -> Element MarkupMsg of module Block.Render . TeX Macros and L0 Function Elements Recall that running text in MicroLaTeX and L0 is represented by a common List Expr type, where type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta Thus both the LaTeX \\italic{stuff} and the L0 [italic stuff] are represented by Fun \"italic\" [Text \"stuff\"] . Values of type Expr are rendered to Html by Expressions are rendered by the function render , the sole export of module Render.Elm : -- Render.Elm render : Int -> Accumulator -> Settings -> Expr -> Element MarkupMsg render generation acc settings expr = ... Expressions of type Fun ... are handled by a dictionary that maps function names to rendering functions: markupDict : Dict String (Int -> Accumulator -> Settings -> List Expr -> Element MarkupMsg) The entries in that dictionary are listed below Function Elements Style i, italic, textit, emph b, bold, strong, textbf bi, boldItalic strike underline large Color red blue green pink magenta violet highlight gray errorHighlight Unclassified and ??? var lambda group skip table image Formatting vspace par Reference bibitem ref reflink eqref cite term term_ footnote label Document hide author date today comment title setcounter abstract Links link href ilink ulink cslink Scripta tags Character, LaTeX dollarSign dollar brackets rb lb bt ds bs texarg backTick underscore mdash ndash Verbatim Elements Under construction -- Render.Block renderVerbatimBlock : Int -> Accumulator -> Settings -> ExpressionBlock -> Element MarkupMsg Verbatim Blocks -- Render.Block and Parser.PrimitiveLaTeXBlock -- 21 blocks equation aligned math code verbatim verse mathmacros textmacros tabular hide docinfo datatable chart svg quiver image tikz load-files include iframe Under construction","title":"Rendering"},{"location":"render/#rendering","text":"render : Int -> Accumulator -> Settings -> ExpressionBlock -> Element MarkupMsg of module Block.Render .","title":"Rendering"},{"location":"render/#tex-macros-and-l0-function-elements","text":"Recall that running text in MicroLaTeX and L0 is represented by a common List Expr type, where type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta Thus both the LaTeX \\italic{stuff} and the L0 [italic stuff] are represented by Fun \"italic\" [Text \"stuff\"] . Values of type Expr are rendered to Html by Expressions are rendered by the function render , the sole export of module Render.Elm : -- Render.Elm render : Int -> Accumulator -> Settings -> Expr -> Element MarkupMsg render generation acc settings expr = ... Expressions of type Fun ... are handled by a dictionary that maps function names to rendering functions: markupDict : Dict String (Int -> Accumulator -> Settings -> List Expr -> Element MarkupMsg) The entries in that dictionary are listed below","title":"TeX Macros and L0 Function Elements"},{"location":"render/#function-elements","text":"","title":"Function Elements"},{"location":"render/#style","text":"i, italic, textit, emph b, bold, strong, textbf bi, boldItalic strike underline large","title":"Style"},{"location":"render/#color","text":"red blue green pink magenta violet highlight gray errorHighlight","title":"Color"},{"location":"render/#unclassified-and","text":"var lambda group skip table image","title":"Unclassified and ???"},{"location":"render/#formatting","text":"vspace par","title":"Formatting"},{"location":"render/#reference","text":"bibitem ref reflink eqref cite term term_ footnote label","title":"Reference"},{"location":"render/#document","text":"hide author date today comment title setcounter abstract","title":"Document"},{"location":"render/#links","text":"link href ilink ulink cslink","title":"Links"},{"location":"render/#scripta","text":"tags","title":"Scripta"},{"location":"render/#character-latex","text":"dollarSign dollar brackets rb lb bt ds bs texarg backTick underscore mdash ndash","title":"Character, LaTeX"},{"location":"render/#verbatim-elements","text":"Under construction -- Render.Block renderVerbatimBlock : Int -> Accumulator -> Settings -> ExpressionBlock -> Element MarkupMsg","title":"Verbatim Elements"},{"location":"render/#verbatim-blocks","text":"-- Render.Block and Parser.PrimitiveLaTeXBlock -- 21 blocks equation aligned math code verbatim verse mathmacros textmacros tabular hide docinfo datatable chart svg quiver image tikz load-files include iframe Under construction","title":"Verbatim Blocks"},{"location":"synchronization/","text":"Synchronization Synchronizing Rendered Text to Source Text The lineNumber field of an ExpressionBlock is used for rendered-text-to-source syncrhonization. Namely, when the user clicks on a piece of rendered text, the message SendLineNumber lineNumber is sent using sendLineNumberOnClick : Int -> Element.Attribute MarkupMsg sendLineNumberOnClick lineNumber = Events.onClick (SendLineNumber (String.fromInt lineNumber)) When the message is handled by the host app and editor, the corresponding source text is scrolled into view and highlighted. (NOTE: still quite innacurate). In both Scripta.io and Scripta Desktop, the message is passed on to the Codemirror editor, whihc does the scrolling and highlighting. PROBLEM: there are still some problems stemming from innaccurate computation of line numbers by the differential parser. To be resolved. Synchronizing Source Text to Rendered Text Although synchronization is carried out by the host app, we outine the process here. First, the user highlights a block of source text, then pressed a button or key combination to send a message from the editor to the Elm app. On the JS side, the editor code for this in Codemirror 6 is attributeChangedCallback(attr, oldVal, newVal) { function sendSelectedText(editor, str) { console.log(\"sendSelectedText (dispatch)\", str) const event = new CustomEvent('selected-text', { 'detail': str , 'bubbles':true, 'composed': true}); editor.dom.dispatchEvent(event); } ... The selected text is handle by onSelectionChange : Html.Attribute FrontendMsg onSelectionChange = textDecoder |> Json.Decode.map SelectedText |> Html.Events.on \"selected-text\" which passes it to the app's (front end) update function in clause SelectedText : SelectedText selectedText -> Frontend.Update.firstSyncLR model selectedText The firstSyncLR function searches the syntax tree (forest) for the given text using ompiler.ASTTools.matchingIdsInAST selectedText model.editRecord.tree This is possible because one field of the corresponding ExpressionBlock is the source text from which it was derived. Once the id(s) for corresponding elements of the rendered text are found, they can be scrolled into view and highlighted.","title":"Synchronization"},{"location":"synchronization/#synchronization","text":"","title":"Synchronization"},{"location":"synchronization/#synchronizing-rendered-text-to-source-text","text":"The lineNumber field of an ExpressionBlock is used for rendered-text-to-source syncrhonization. Namely, when the user clicks on a piece of rendered text, the message SendLineNumber lineNumber is sent using sendLineNumberOnClick : Int -> Element.Attribute MarkupMsg sendLineNumberOnClick lineNumber = Events.onClick (SendLineNumber (String.fromInt lineNumber)) When the message is handled by the host app and editor, the corresponding source text is scrolled into view and highlighted. (NOTE: still quite innacurate). In both Scripta.io and Scripta Desktop, the message is passed on to the Codemirror editor, whihc does the scrolling and highlighting. PROBLEM: there are still some problems stemming from innaccurate computation of line numbers by the differential parser. To be resolved.","title":"Synchronizing Rendered Text to Source Text"},{"location":"synchronization/#synchronizing-source-text-to-rendered-text","text":"Although synchronization is carried out by the host app, we outine the process here. First, the user highlights a block of source text, then pressed a button or key combination to send a message from the editor to the Elm app. On the JS side, the editor code for this in Codemirror 6 is attributeChangedCallback(attr, oldVal, newVal) { function sendSelectedText(editor, str) { console.log(\"sendSelectedText (dispatch)\", str) const event = new CustomEvent('selected-text', { 'detail': str , 'bubbles':true, 'composed': true}); editor.dom.dispatchEvent(event); } ... The selected text is handle by onSelectionChange : Html.Attribute FrontendMsg onSelectionChange = textDecoder |> Json.Decode.map SelectedText |> Html.Events.on \"selected-text\" which passes it to the app's (front end) update function in clause SelectedText : SelectedText selectedText -> Frontend.Update.firstSyncLR model selectedText The firstSyncLR function searches the syntax tree (forest) for the given text using ompiler.ASTTools.matchingIdsInAST selectedText model.editRecord.tree This is possible because one field of the corresponding ExpressionBlock is the source text from which it was derived. Once the id(s) for corresponding elements of the rendered text are found, they can be scrolled into view and highlighted.","title":"Synchronizing Source Text to Rendered Text"},{"location":"tests/","text":"Tests To implement: round-trip tests for microLaTeX using the pretty-printer:","title":"Tests"},{"location":"tests/#tests","text":"To implement: round-trip tests for microLaTeX using the pretty-printer:","title":"Tests"},{"location":"l0/l0/","text":"L0 Ho ho ho!","title":"L0"},{"location":"l0/l0/#l0","text":"Ho ho ho!","title":"L0"}]}